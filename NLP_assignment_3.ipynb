{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP assignment 3",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR0_y5b57xzE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string \n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpsmFyZW71h1",
        "colab_type": "code",
        "outputId": "c953363c-315f-4438-d489-b1812687a994",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDCOVZw274HD",
        "colab_type": "code",
        "outputId": "9fc41427-77b2-41d4-c5cf-9328ed3927f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "train_ = pd.read_csv('/content/drive/My Drive/train.csv', delimiter=\"\\t\")\n",
        "test_=pd.read_csv('/content/drive/My Drive/test.csv', delimiter=\"\\t\")\n",
        "print(train_.head())\n",
        "print(test_.head())"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            meta  uid sentiment\n",
            "0           meta    3  negative\n",
            "1              @    O       NaN\n",
            "2  AdilNisarButt  Hin       NaN\n",
            "3       pakistan  Hin       NaN\n",
            "4             ka  Hin       NaN\n",
            "              meta  uid sentiment\n",
            "0             meta    8   neutral\n",
            "1               RT  Eng       NaN\n",
            "2                @    O       NaN\n",
            "3  UAAPconfessions  Eng       NaN\n",
            "4             Love  Eng       NaN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guJ0ixtj7-HR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extractdat(dataframe):\n",
        "  data = dataframe.loc[:,['meta','sentiment']]\n",
        "  t = \"\"\n",
        "  x = list()\n",
        "  y = list()\n",
        "  for i in range(data.shape[0]):\n",
        "    if(data.iloc[i,0]==\"meta\"):\n",
        "      x.append(t.strip())\n",
        "      y.append(str(data.iloc[i,1]))\n",
        "      t=\"\"\n",
        "    else:\n",
        "      t += (str(data.iloc[i,0])+\" \")\n",
        "  \n",
        "  x.append(t.strip())\n",
        "  \n",
        "  return x[1:], y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rukOaNz-8Beo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, Y_train = extractdat(train_)\n",
        "X_test, Y_test = extractdat(test_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9STP0-D8S_U",
        "colab_type": "code",
        "outputId": "bbd25978-c0ca-4c34-d289-8496d738228a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(len(X_train), len(Y_train), len(X_test), len(Y_test))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13524 13524 1869 1869\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oDNcc4j8XLD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean(text, tknzr):\n",
        "  tweet_tokens = tknzr.tokenize(text)\n",
        "  t = \"\"\n",
        "  for j in tweet_tokens:\n",
        "    if(j not in string.punctuation and j not in ['â€¦']):\n",
        "      t += (j.lower())\n",
        "      t+=\" \"\n",
        "  return t.strip()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ke02W2RI8Zco",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tknzr = TweetTokenizer(strip_handles=True, reduce_len=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSDuw8sA8aWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(X_train)):\n",
        "  X_train[i]=(clean(X_train[i],tknzr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsp7D7_Y8gcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(X_test)):\n",
        "  X_test[i]=(clean(X_test[i], tknzr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Teuale5x8lYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tk = Tokenizer(num_words=None, char_level=True, oov_token='UNK')\n",
        "tk.fit_on_texts(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqFHDDv68ncg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = tk.texts_to_sequences(X_train)\n",
        "X_test = tk.texts_to_sequences(X_test)\n",
        "tweets_lengths = list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUPAzlFJ81eB",
        "colab_type": "code",
        "outputId": "9ba89e36-927f-4980-d6aa-8ba50593c109",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "X_train = pad_sequences(X_train, maxlen=200, padding='post')\n",
        "X_test = pad_sequences(X_test, maxlen=200, padding='post')\n",
        "X_train = np.array(X_train, dtype='float32')\n",
        "X_test = np.array(X_test, dtype='float32')\n",
        "from keras.utils import to_categorical\n",
        "def categorize(arr):\n",
        "  cat = list()\n",
        "  for i in arr:\n",
        "    if(i == \"positive\"):\n",
        "      cat.append(0)\n",
        "    elif(i == \"negative\"):\n",
        "      cat.append(1)\n",
        "    else:\n",
        "      cat.append(2)\n",
        "  cat = np.array(cat,dtype='float32')\n",
        "  categorical = to_categorical(cat)\n",
        "  return categorical\n",
        "\n",
        "Y_train = categorize(Y_train)\n",
        "Y_test = categorize(Y_test)\n",
        "print(len(Y_test))\n",
        "print(len(X_test))\n",
        "vocab_size = len(tk.word_index)\n",
        "print(vocab_size)\n",
        "embedding_weights = []\n",
        "for char, i in tk.word_index.items():\n",
        "    onehot = np.zeros(vocab_size)\n",
        "    onehot[i - 1] = 1\n",
        "    embedding_weights.append(onehot)\n",
        "embedding_weights = np.array(embedding_weights)\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1869\n",
            "1869\n",
            "880\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AAAoTa49MDc",
        "colab_type": "code",
        "outputId": "29875ff0-8e31-47eb-c463-93e6accd5c12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Input, Conv1D, GlobalMaxPool1D, Embedding, Flatten, Dropout, MaxPooling1D\n",
        "from keras.layers import LSTM, Lambda, TimeDistributed, Bidirectional, concatenate\n",
        "embedding_size = vocab_size\n",
        "conv_layers = [[256, 7, 3], [256, 7, 3], [256, 3, -1],[256, 3, -1], [256, 3, -1],[256, 3, 3]]\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length = 200, weights=[embedding_weights]))\n",
        "for i, j, k in conv_layers:\n",
        "    model.add(Conv1D(i, j, activation='relu'))\n",
        "    if k != -1:\n",
        "        model.add(MaxPooling1D(pool_size=k))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=1024, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(units=1024, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(units=3, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 200, 880)          774400    \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 194, 256)          1577216   \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 64, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 58, 256)           459008    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 19, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 17, 256)           196864    \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 15, 256)           196864    \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 13, 256)           196864    \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 11, 256)           196864    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 3, 256)            0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              787456    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 3075      \n",
            "=================================================================\n",
            "Total params: 5,438,211\n",
            "Trainable params: 5,438,211\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie4zgZCRsG6B",
        "colab_type": "code",
        "outputId": "a1a6aeab-bd53-436b-a40c-57b3c75200cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(len(X_test),len(Y_test))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1869 1869\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3s7nFyuMsLcq",
        "colab_type": "code",
        "outputId": "cb5672b4-1fa0-438c-d2fa-abb8d23c409d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(len(X_train),len(Y_train))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13524 13524\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4836rOCsTJd",
        "colab_type": "code",
        "outputId": "f3d61886-c964-44a8-8b5f-b7f39d6c1e9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=128, epochs=30, validation_data=(X_test, Y_test), verbose=1)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 13524 samples, validate on 1869 samples\n",
            "Epoch 1/30\n",
            "13524/13524 [==============================] - 9s 675us/step - loss: 1.0675 - acc: 0.4019 - val_loss: 1.0498 - val_acc: 0.4312\n",
            "Epoch 2/30\n",
            "13524/13524 [==============================] - 4s 316us/step - loss: 0.9852 - acc: 0.4873 - val_loss: 0.9995 - val_acc: 0.4799\n",
            "Epoch 3/30\n",
            "13524/13524 [==============================] - 4s 314us/step - loss: 0.9027 - acc: 0.5603 - val_loss: 1.0749 - val_acc: 0.4708\n",
            "Epoch 4/30\n",
            "13524/13524 [==============================] - 4s 315us/step - loss: 0.8396 - acc: 0.6060 - val_loss: 1.0115 - val_acc: 0.5099\n",
            "Epoch 5/30\n",
            "13524/13524 [==============================] - 4s 315us/step - loss: 0.7828 - acc: 0.6352 - val_loss: 1.0279 - val_acc: 0.5190\n",
            "Epoch 6/30\n",
            "13524/13524 [==============================] - 4s 314us/step - loss: 0.6990 - acc: 0.6942 - val_loss: 1.0970 - val_acc: 0.5302\n",
            "Epoch 7/30\n",
            "13524/13524 [==============================] - 4s 317us/step - loss: 0.6178 - acc: 0.7374 - val_loss: 1.2676 - val_acc: 0.5099\n",
            "Epoch 8/30\n",
            "13524/13524 [==============================] - 4s 317us/step - loss: 0.5052 - acc: 0.7955 - val_loss: 1.2538 - val_acc: 0.5276\n",
            "Epoch 9/30\n",
            "13524/13524 [==============================] - 4s 318us/step - loss: 0.4166 - acc: 0.8409 - val_loss: 1.7390 - val_acc: 0.4960\n",
            "Epoch 10/30\n",
            "13524/13524 [==============================] - 4s 318us/step - loss: 0.3288 - acc: 0.8768 - val_loss: 1.6617 - val_acc: 0.5195\n",
            "Epoch 11/30\n",
            "13524/13524 [==============================] - 4s 315us/step - loss: 0.2392 - acc: 0.9169 - val_loss: 1.8202 - val_acc: 0.5099\n",
            "Epoch 12/30\n",
            "13524/13524 [==============================] - 4s 315us/step - loss: 0.1998 - acc: 0.9313 - val_loss: 1.8303 - val_acc: 0.5286\n",
            "Epoch 13/30\n",
            "13524/13524 [==============================] - 4s 313us/step - loss: 0.1484 - acc: 0.9528 - val_loss: 2.0734 - val_acc: 0.5104\n",
            "Epoch 14/30\n",
            "13524/13524 [==============================] - 4s 315us/step - loss: 0.1330 - acc: 0.9579 - val_loss: 2.1704 - val_acc: 0.5217\n",
            "Epoch 15/30\n",
            "13524/13524 [==============================] - 4s 317us/step - loss: 0.1081 - acc: 0.9687 - val_loss: 2.4120 - val_acc: 0.5056\n",
            "Epoch 16/30\n",
            "13524/13524 [==============================] - 4s 317us/step - loss: 0.1126 - acc: 0.9664 - val_loss: 2.2929 - val_acc: 0.5222\n",
            "Epoch 17/30\n",
            "13524/13524 [==============================] - 4s 313us/step - loss: 0.0868 - acc: 0.9743 - val_loss: 2.5117 - val_acc: 0.5174\n",
            "Epoch 18/30\n",
            "13524/13524 [==============================] - 4s 314us/step - loss: 0.0983 - acc: 0.9701 - val_loss: 2.3584 - val_acc: 0.4992\n",
            "Epoch 19/30\n",
            "13524/13524 [==============================] - 4s 316us/step - loss: 0.0898 - acc: 0.9723 - val_loss: 2.2960 - val_acc: 0.5115\n",
            "Epoch 20/30\n",
            "13524/13524 [==============================] - 4s 314us/step - loss: 0.0678 - acc: 0.9797 - val_loss: 2.5275 - val_acc: 0.5227\n",
            "Epoch 21/30\n",
            "13524/13524 [==============================] - 4s 316us/step - loss: 0.0713 - acc: 0.9774 - val_loss: 2.5318 - val_acc: 0.5094\n",
            "Epoch 22/30\n",
            "13524/13524 [==============================] - 4s 317us/step - loss: 0.0654 - acc: 0.9782 - val_loss: 2.7274 - val_acc: 0.5222\n",
            "Epoch 23/30\n",
            "13524/13524 [==============================] - 4s 316us/step - loss: 0.0643 - acc: 0.9786 - val_loss: 2.6402 - val_acc: 0.5099\n",
            "Epoch 24/30\n",
            "13524/13524 [==============================] - 4s 316us/step - loss: 0.0790 - acc: 0.9734 - val_loss: 2.9317 - val_acc: 0.5185\n",
            "Epoch 25/30\n",
            "13524/13524 [==============================] - 4s 316us/step - loss: 0.0583 - acc: 0.9787 - val_loss: 2.6599 - val_acc: 0.5045\n",
            "Epoch 26/30\n",
            "13524/13524 [==============================] - 4s 314us/step - loss: 0.0551 - acc: 0.9825 - val_loss: 2.8917 - val_acc: 0.5029\n",
            "Epoch 27/30\n",
            "13524/13524 [==============================] - 4s 314us/step - loss: 0.0572 - acc: 0.9798 - val_loss: 3.0070 - val_acc: 0.5099\n",
            "Epoch 28/30\n",
            "13524/13524 [==============================] - 4s 317us/step - loss: 0.0657 - acc: 0.9770 - val_loss: 2.9108 - val_acc: 0.5035\n",
            "Epoch 29/30\n",
            "13524/13524 [==============================] - 4s 316us/step - loss: 0.0546 - acc: 0.9811 - val_loss: 3.3404 - val_acc: 0.5062\n",
            "Epoch 30/30\n",
            "13524/13524 [==============================] - 4s 315us/step - loss: 0.0591 - acc: 0.9797 - val_loss: 3.0202 - val_acc: 0.5067\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f97da50d1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    }
  ]
}